{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import re\n",
    "import cPickle, gzip\n",
    "import progressbar\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import parser.Smipar as Smipar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1094235 of 1094235) |################| Elapsed Time: 0:00:13 Time: 0:00:13\n"
     ]
    }
   ],
   "source": [
    "# rsmi data reloader\n",
    "\n",
    "data_directory = 'data'\n",
    "processed_data_filename = 'processed_data.pkl.gz'\n",
    "processed_data_filepath = os.path.join(data_directory, processed_data_filename)\n",
    "data_length = 1094235\n",
    "\n",
    "bar = progressbar.ProgressBar(max_value=data_length)\n",
    "\n",
    "rsmi_data = []\n",
    "\n",
    "with gzip.open(processed_data_filepath, 'rb') as data_file:\n",
    "    i = 1\n",
    "    while 1:\n",
    "        try:\n",
    "            line, ref = cPickle.load(data_file)\n",
    "            rsmi_data.append((line, ref))\n",
    "        except EOFError:\n",
    "            break\n",
    "        bar.update(i)\n",
    "        i += 1\n",
    "        \n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data reloader\n",
    "\n",
    "with gzip.open('data/vocab/vocab_dict.pkl.gz', 'rb') as dict_file:\n",
    "    vocab_reactants, vocab_products = cPickle.load(dict_file)\n",
    "\n",
    "with gzip.open('data/vocab/vocab_list.pkl.gz', 'rb') as list_file:\n",
    "    reactants_token_list, products_token_list = cPickle.load(list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cano(smiles): # canonicalize smiles by MolToSmiles function\n",
    "    return Chem.MolToSmiles(Chem.MolFromSmiles(smiles)) if (smiles != '') else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1094235 of 1094235) |################| Elapsed Time: 3:57:49 Time: 3:57:49\n"
     ]
    }
   ],
   "source": [
    "bar = progressbar.ProgressBar(max_value=data_length)\n",
    "\n",
    "token_len = []\n",
    "\n",
    "error_rsmi = {}\n",
    "\n",
    "with gzip.open('data/training_data.pkl.gz', 'wb') as training_file:\n",
    "    \n",
    "    for i, rsmi in enumerate(rsmi_data):\n",
    "\n",
    "        rsmi = rsmi[0]\n",
    "        \n",
    "        reactant_list = []\n",
    "        agent_list = []\n",
    "        product_list = []\n",
    "        \n",
    "        try:\n",
    "            split_rsmi = rsmi.split('>')\n",
    "            reactants = cano(split_rsmi[0]).split('.')\n",
    "            agents = cano(split_rsmi[1]).split('.')\n",
    "            products = cano(split_rsmi[2]).split('.')\n",
    "\n",
    "            for reactant in reactants:\n",
    "                reactant_list += Smipar.parser_list(reactant)\n",
    "                reactant_list += '.'\n",
    "            for agent in agents:\n",
    "                agent_list += Smipar.parser_list(agent)\n",
    "                agent_list += '.'\n",
    "            for product in products:\n",
    "                product_list += Smipar.parser_list(product)\n",
    "                product_list += '.'\n",
    "\n",
    "            reactant_list.pop() # to pop last '.'\n",
    "            agent_list.pop()\n",
    "            product_list.pop()\n",
    "\n",
    "            reactant_list += '>'\n",
    "            reactant_list += agent_list\n",
    "\n",
    "            token_len.append((len(reactant_list), len(product_list)))\n",
    "\n",
    "            cPickle.dump(([reactants_token_list.index(r) for r in reactant_list],\n",
    "                          [products_token_list.index(p) for p in product_list],\n",
    "                          rsmi[1]), training_file, 2)\n",
    "        except:\n",
    "            error_rsmi.update({i: rsmi})\n",
    "\n",
    "        bar.update(i)\n",
    "        \n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 81\n"
     ]
    }
   ],
   "source": [
    "trans = zip(*token_len)\n",
    "print(max(trans[0]), max(trans[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 1093874\n",
      "cut: [380164, 665166, 898558, 1093865]\n"
     ]
    }
   ],
   "source": [
    "print(\"total:\", len(token_len))\n",
    "count = [0, 0, 0, 0]\n",
    "for length in token_len:\n",
    "    if(length[0] < 150 and length[1] < 80):\n",
    "        count[3] += 1\n",
    "        if(length[0] < 90 and length[1] < 65):\n",
    "            count[2] += 1\n",
    "            if(length[0] < 70 and length[1] < 60):\n",
    "                count[1] += 1\n",
    "                if(length[0] < 54 and length[1] < 54):\n",
    "                    count[0] += 1\n",
    "print(\"cut:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (1093645 of 1093874) |################ | Elapsed Time: 0:03:21 ETA: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10938 1082936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100% (1093874 of 1093874) |################| Elapsed Time: 0:03:21 ETA:  0:00:00\r",
      "100% (1093874 of 1093874) |################| Elapsed Time: 0:03:21 Time: 0:03:21\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "bar = progressbar.ProgressBar(max_value=len(token_len))\n",
    "with gzip.open('data/training_data.pkl.gz', 'rb') as data_file:\n",
    "    with gzip.open('data/train.pkl.gz', 'wb') as train_file:\n",
    "        with gzip.open('data/dev.pkl.gz', 'wb') as dev_file:\n",
    "            i = 1\n",
    "            while 1:\n",
    "                try:\n",
    "                    reactants, products, _ = cPickle.load(data_file)\n",
    "                    if i%100:\n",
    "                        cPickle.dump((reactants, products), train_file, 2)\n",
    "                    else:\n",
    "                        cPickle.dump((reactants, products), dev_file, 2)\n",
    "                        count += 1\n",
    "                except EOFError:\n",
    "                    break\n",
    "                bar.update(i)\n",
    "                i += 1\n",
    "\n",
    "bar.finish()\n",
    "print(count, len(token_len)-count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
